{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85419d6d",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "475234b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import math\n",
    "import traceback\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac08b8c",
   "metadata": {},
   "source": [
    "# Load files with news urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96d0c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_df =  pd.read_excel(\"news_id_url.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2d898c",
   "metadata": {},
   "source": [
    "# Extract accounts in news urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "428976db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step is previuesly in a spearte python code . the file name are \"scraping_beamreport_accounts_final.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d08d995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1 done. Accounts collected so far: 148\n",
      "\n",
      "Batch 2 done. Accounts collected so far: 165\n",
      "\n",
      "Batch 3 done. Accounts collected so far: 132\n",
      "\n",
      "Batch 4 done. Accounts collected so far: 138\n",
      "\n",
      "Batch 5 done. Accounts collected so far: 177\n",
      "\n",
      "Batch 6 done. Accounts collected so far: 266\n",
      "\n",
      "Batch 7 done. Accounts collected so far: 26\n",
      "\n",
      "Batch 8 done. Accounts collected so far: 126\n",
      "\n",
      "Batch 9 done. Accounts collected so far: 174\n",
      "\n",
      "Batch 10 done. Accounts collected so far: 111\n",
      "\n",
      "Batch 11 done. Accounts collected so far: 77\n"
     ]
    }
   ],
   "source": [
    "accounts = []\n",
    "unlabeled_news = []\n",
    "\n",
    "news_num = urls_df.shape[0]\n",
    "batch_size = 50\n",
    "loops_num = math.ceil(news_num / batch_size)\n",
    "\n",
    "df_counter = 0\n",
    "\n",
    "for i in range(loops_num):\n",
    "    counter = 0\n",
    "    error_log_filename = f\"accounts_data/error_log_file_{i + 1}.txt\"\n",
    "    \n",
    "    with open(error_log_filename, \"w\", encoding=\"utf-8\") as log_file:\n",
    "        while counter < batch_size and df_counter < news_num:\n",
    "            try:\n",
    "                current_news_id = urls_df.at[df_counter,\"news_id\"]\n",
    "                current_url = urls_df.at[df_counter, 'link']\n",
    "                \n",
    "                response = requests.get(current_url, timeout=10)\n",
    "                response.raise_for_status()\n",
    "                html_text = response.text\n",
    "                soup = BeautifulSoup(html_text, 'lxml')\n",
    "\n",
    "                temp_divs = soup.find_all(\n",
    "                    'div',\n",
    "                    attrs={\n",
    "                        'data-element_type': \"widget\",\n",
    "                        'data-widget_type': \"icon-list.default\"\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    label = temp_divs[1].text.strip()\n",
    "                    \n",
    "                    if not label:\n",
    "                        raise ValueError(\"Label text is empty.\")\n",
    "                except:\n",
    "                    unlabeled_news.append(current_news_id)\n",
    "                    df_counter += 1\n",
    "                    counter += 1\n",
    "                    continue\n",
    "                        \n",
    "                table = soup.find('table')\n",
    "                if table is None:\n",
    "                    log_file.write(f\"[MissingTable] News ID: {current_news_id} | URL: {current_url}\\n\")\n",
    "                    df_counter += 1\n",
    "                    counter += 1\n",
    "                    continue\n",
    "                \n",
    "                tr_elements = table.find_all('tr')\n",
    "                \n",
    "                if len(tr_elements) == 0:\n",
    "                    log_file.write(f\"[EmptyTable] News ID: {current_news_id} | URL: {current_url}\\n\")\n",
    "                    df_counter += 1\n",
    "                    counter += 1\n",
    "                    continue\n",
    "                \n",
    "                for r,tr in enumerate(tr_elements):\n",
    "                    try:\n",
    "                        td_elements = tr.find_all('td')\n",
    "                            \n",
    "                        account_info = {\n",
    "                            'row_table_number': r+1,\n",
    "                            'account_url': 'undefined',\n",
    "                            'account_name': 'undefined',\n",
    "                            'followers_number': 'undefined',\n",
    "                            'label': temp_divs[1].text.strip(),\n",
    "                            'news_id': current_news_id\n",
    "                        }\n",
    "\n",
    "                        def clean_text(element):\n",
    "                            \"\"\"Safely extract text content from an HTML element, replacing &nbsp; and stripping whitespace.\"\"\"\n",
    "                            if element:\n",
    "                                text = element.get_text()\n",
    "                                if text and text.replace('\\xa0', '').strip():  # Check if not just &nbsp;\n",
    "                                    return text.replace('\\xa0', ' ').strip()\n",
    "                            return 'undefined'\n",
    "\n",
    "\n",
    "                        account_info['account_url'] = td_elements[1].select_one('a')['href'] if td_elements[1].select_one('a') else 'undefined'\n",
    "                        account_info['account_name'] = clean_text(td_elements[1])\n",
    "                        account_info['followers_number'] = clean_text(td_elements[2])\n",
    "\n",
    "                        accounts.append(account_info)\n",
    "                \n",
    "                    except Exception as e:\n",
    "                        log_file.write(f\"[RowParseError] News ID: {current_news_id} | {current_url} | {str(e)}\\n\")\n",
    "                        continue\n",
    "\n",
    "            except requests.exceptions.RequestException as net_err:\n",
    "                # Network error: save current accounts and exit\n",
    "                log_file.write(f\"[NetworkError] News ID: {current_news_id} | URL: {current_url} | {str(net_err)}\\n\")\n",
    "                log_file.write(\"Network error occurred. Saving current progress and exiting.\\n\")\n",
    "\n",
    "                df = pd.DataFrame(accounts)\n",
    "                df.to_csv(\"accounts_info_uncompleted.csv\", index=False, encoding='utf-8-sig')\n",
    "                print(\"Network error. Progress saved to 'accounts_info_uncompleted.csv'. Exiting.\")\n",
    "                exit()\n",
    "\n",
    "            except Exception as e:\n",
    "                # Any other unexpected error\n",
    "                log_file.write(f\"[UnknownError] News ID: {current_news_id} | URL: {current_url}\\n\")\n",
    "                log_file.write(traceback.format_exc() + \"\\n\")\n",
    "\n",
    "            df_counter += 1\n",
    "            counter += 1\n",
    "\n",
    "    # Save the accounts of this batch\n",
    "    print(f\"\\nBatch {i + 1} done. Accounts collected so far: {len(accounts)}\")\n",
    "    df = pd.DataFrame(accounts)\n",
    "    df.to_csv(f\"accounts_data/accounts_info_file_{i+1}.csv\", index=False, encoding='utf-8-sig')\n",
    "    accounts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cc494d",
   "metadata": {},
   "source": [
    "# Merge account files in one file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36c50329",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_accounts_files = 11\n",
    "dfs_holder =[]\n",
    "\n",
    "for i in range(1,num_accounts_files+1):\n",
    "    df = pd.read_csv(f\"accounts_data/accounts_info_file_{i}.csv\")\n",
    "    dfs_holder.append(df)\n",
    "    \n",
    "main_df = pd.concat(dfs_holder,ignore_index=True)\n",
    "#main_df['news_id'] = pd.to_numeric(main_df['news_id'], errors='coerce')\n",
    "main_df = main_df.sort_values(by=[\"news_id\",\"row_table_number\"],ascending=[True,True])\n",
    "\n",
    "main_df.to_csv(\"accounts_data/accounts_info_file_merged.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a09fc",
   "metadata": {},
   "source": [
    "# saving a file containing news with no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4f2e34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of news with no labels exist:  65\n"
     ]
    }
   ],
   "source": [
    "no_labels_df = pd.DataFrame(unlabeled_news)\n",
    "\n",
    "print(\"number of news with no labels exist: \",no_labels_df.shape[0])\n",
    "no_labels_df.to_csv(\"accounts_data/news_no_labels_file.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5a05e0",
   "metadata": {},
   "source": [
    "# analysis values of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2f05671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in main_df:  1540\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_table_number</th>\n",
       "      <th>account_url</th>\n",
       "      <th>account_name</th>\n",
       "      <th>followers_number</th>\n",
       "      <th>label</th>\n",
       "      <th>news_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/share/p/1AytsiHgrd/</td>\n",
       "      <td>قوات العمل الخاص هيئة العمليات</td>\n",
       "      <td>(697) ألف متابع</td>\n",
       "      <td>مضلل</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.facebook.com/share/p/15pwXprDjz/</td>\n",
       "      <td>عروض تذاكر بدر وتاركو للطيران</td>\n",
       "      <td>(319) ألف متابع</td>\n",
       "      <td>مضلل</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.facebook.com/share/p/1DvNK8fbi9/</td>\n",
       "      <td>ارصاد منذر أحمد الحاج</td>\n",
       "      <td>(89) ألف متابع</td>\n",
       "      <td>مضلل</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/share/p/1EjSjxii6k/</td>\n",
       "      <td>قوات العمل الخاص هيئة العمليات</td>\n",
       "      <td>1</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.facebook.com/share/p/1GGMLwQhjv/</td>\n",
       "      <td>شبكة لمتنا الإخبارية</td>\n",
       "      <td>2</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_table_number                                   account_url  \\\n",
       "0                 1  https://www.facebook.com/share/p/1AytsiHgrd/   \n",
       "1                 2  https://www.facebook.com/share/p/15pwXprDjz/   \n",
       "2                 3  https://www.facebook.com/share/p/1DvNK8fbi9/   \n",
       "3                 1  https://www.facebook.com/share/p/1EjSjxii6k/   \n",
       "4                 2  https://www.facebook.com/share/p/1GGMLwQhjv/   \n",
       "\n",
       "                     account_name followers_number  label  news_id  \n",
       "0  قوات العمل الخاص هيئة العمليات  (697) ألف متابع   مضلل        1  \n",
       "1   عروض تذاكر بدر وتاركو للطيران  (319) ألف متابع   مضلل        1  \n",
       "2           ارصاد منذر أحمد الحاج   (89) ألف متابع   مضلل        1  \n",
       "3  قوات العمل الخاص هيئة العمليات                1  مفبرك        2  \n",
       "4            شبكة لمتنا الإخبارية                2  مفبرك        2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading last account file saved so far\n",
    "\n",
    "main_df = pd.read_csv(\"accounts_data/accounts_info_file_merged.csv\")\n",
    "print(\"number of rows in main_df: \",main_df.shape[0])\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd168d",
   "metadata": {},
   "source": [
    "Now, we will look at undefined values in the file and in which columns it appears to know more about how to overcome extraction problems (if possible). four columns can be analyzed, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b2291e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of undefined labels:  0\n",
      "number of undefined accounts name :  3\n",
      "number of undefined followers_number :  4\n",
      "number of undefined account_url :  86\n"
     ]
    }
   ],
   "source": [
    "def evaluate_df(df):\n",
    "    \n",
    "    #label column\n",
    "    condition = (df['label'].isna()) | (df['label'].astype(str).str.strip().str.len() == 0)\n",
    "\n",
    "    print(\"number of undefined labels: \",condition.sum())\n",
    "    #account_name column\n",
    "    condition = df['account_name'] == 'undefined'\n",
    "    print(\"number of undefined accounts name : \",condition.sum())\n",
    "\n",
    "    #followers_number column\n",
    "    condition = df['followers_number'] == 'undefined'\n",
    "    print(\"number of undefined followers_number : \",condition.sum())\n",
    "\n",
    "    #account_url column\n",
    "    condition = df['account_url'] == 'undefined'\n",
    "    print(\"number of undefined account_url : \",condition.sum())\n",
    "    \n",
    "\n",
    "evaluate_df(main_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9314883d",
   "metadata": {},
   "source": [
    "### remove unwanted rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0379c98a",
   "metadata": {},
   "source": [
    "There are unwanted rows in the main_df, it can be identified using certain values in followers number column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ba7a2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unwanted rows in main_df:  77\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_table_number</th>\n",
       "      <th>account_url</th>\n",
       "      <th>account_name</th>\n",
       "      <th>followers_number</th>\n",
       "      <th>label</th>\n",
       "      <th>news_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1</td>\n",
       "      <td>undefined</td>\n",
       "      <td>الصفحة/ الموقع الإلكتروني</td>\n",
       "      <td>عدد المتابعين</td>\n",
       "      <td>مضلل</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>1</td>\n",
       "      <td>undefined</td>\n",
       "      <td>اسم الصفحة \\ الحساب</td>\n",
       "      <td>عدد المتابعين</td>\n",
       "      <td>مضلل</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>undefined</td>\n",
       "      <td>الحساب \\ الصفحة\\ المجموعة</td>\n",
       "      <td>عدد المتابعين \\ الأعضاء</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1</td>\n",
       "      <td>undefined</td>\n",
       "      <td>اسم الحساب \\ الصفحة</td>\n",
       "      <td>عدد المتابعين</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>undefined</td>\n",
       "      <td>اسم الصفحة \\ الحساب</td>\n",
       "      <td>عدد المتابعين</td>\n",
       "      <td>انتقائي</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_table_number account_url               account_name  \\\n",
       "398                 1   undefined  الصفحة/ الموقع الإلكتروني   \n",
       "716                 1   undefined        اسم الصفحة \\ الحساب   \n",
       "739                 1   undefined  الحساب \\ الصفحة\\ المجموعة   \n",
       "763                 1   undefined        اسم الحساب \\ الصفحة   \n",
       "767                 1   undefined        اسم الصفحة \\ الحساب   \n",
       "\n",
       "            followers_number    label  news_id  \n",
       "398            عدد المتابعين     مضلل      132  \n",
       "716            عدد المتابعين     مضلل      240  \n",
       "739  عدد المتابعين \\ الأعضاء    مفبرك      246  \n",
       "763            عدد المتابعين    مفبرك      252  \n",
       "767            عدد المتابعين  انتقائي      253  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unwanted_vals = ['عدد المتابعات','عدد المتابعين \\\\ الأعضاء','عدد المتابعيين','عدد المتابعين']\n",
    "\n",
    "condition = main_df[\"followers_number\"].isin(unwanted_vals)\n",
    "print(\"number of unwanted rows in main_df: \",condition.sum())\n",
    "\n",
    "#see a sample from this rows\n",
    "main_df[condition].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b6675",
   "metadata": {},
   "source": [
    "#### remove them from main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec3a16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in main_df after removing unwanted rows:  1463\n"
     ]
    }
   ],
   "source": [
    "#remove them from main_df\n",
    "main_df = main_df[~condition].reset_index(drop=True)\n",
    "print(\"number of rows in main_df after removing unwanted rows: \",main_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6cd6605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of undefined labels:  0\n",
      "number of undefined accounts name :  3\n",
      "number of undefined followers_number :  4\n",
      "number of undefined account_url :  9\n"
     ]
    }
   ],
   "source": [
    "evaluate_df(main_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ec673",
   "metadata": {},
   "source": [
    "### look at news urls with undefined account_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5df4bcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_table_number</th>\n",
       "      <th>account_url</th>\n",
       "      <th>account_name</th>\n",
       "      <th>followers_number</th>\n",
       "      <th>label</th>\n",
       "      <th>news_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>7</td>\n",
       "      <td>undefined</td>\n",
       "      <td>undefined</td>\n",
       "      <td>undefined</td>\n",
       "      <td>مضلل</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>6</td>\n",
       "      <td>undefined</td>\n",
       "      <td>undefined</td>\n",
       "      <td>undefined</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>8</td>\n",
       "      <td>undefined</td>\n",
       "      <td>undefined</td>\n",
       "      <td>undefined</td>\n",
       "      <td>مضلل</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>1</td>\n",
       "      <td>undefined</td>\n",
       "      <td>CH-3</td>\n",
       "      <td>CH-4</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>2</td>\n",
       "      <td>undefined</td>\n",
       "      <td>256 كلم\\الساعة</td>\n",
       "      <td>180 كلم\\الساعة</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>3</td>\n",
       "      <td>undefined</td>\n",
       "      <td>2400 كلم</td>\n",
       "      <td>5000 كلم</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>4</td>\n",
       "      <td>undefined</td>\n",
       "      <td>180 كجم</td>\n",
       "      <td>350 كجم</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>5</td>\n",
       "      <td>undefined</td>\n",
       "      <td>12 ساعة</td>\n",
       "      <td>30-40 ساعة</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>6</td>\n",
       "      <td>undefined</td>\n",
       "      <td>صاروخ جو أرض (AR-1)</td>\n",
       "      <td>صواريخ جو أرض موجهة بالليزرقنابل موجهة بالليزر...</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_table_number account_url         account_name  \\\n",
       "790                  7   undefined            undefined   \n",
       "808                  6   undefined            undefined   \n",
       "873                  8   undefined            undefined   \n",
       "1385                 1   undefined                 CH-3   \n",
       "1386                 2   undefined       256 كلم\\الساعة   \n",
       "1387                 3   undefined             2400 كلم   \n",
       "1388                 4   undefined              180 كجم   \n",
       "1389                 5   undefined              12 ساعة   \n",
       "1390                 6   undefined  صاروخ جو أرض (AR-1)   \n",
       "\n",
       "                                       followers_number  label  news_id  \n",
       "790                                           undefined   مضلل      258  \n",
       "808                                           undefined  مفبرك      262  \n",
       "873                                           undefined   مضلل      274  \n",
       "1385                                               CH-4  مفبرك      499  \n",
       "1386                                     180 كلم\\الساعة  مفبرك      499  \n",
       "1387                                           5000 كلم  مفبرك      499  \n",
       "1388                                            350 كجم  مفبرك      499  \n",
       "1389                                         30-40 ساعة  مفبرك      499  \n",
       "1390  صواريخ جو أرض موجهة بالليزرقنابل موجهة بالليزر...  مفبرك      499  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = (main_df['account_url'] == 'undefined')\n",
    "\n",
    "main_df[condition].head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f9e1886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n",
      "https://www.beamreports.com/2024/03/09/%d9%85%d8%a7-%d8%ad%d9%82%d9%8a%d9%82%d8%a9-%d8%b5%d9%88%d8%b1-%d8%ae%d8%b1%d9%88%d8%ac-%d8%a7%d9%84%d8%a8%d8%b4%d9%8a%d8%b1-%d9%85%d9%86-%d9%85%d8%b3%d8%aa%d8%b4%d9%81%d9%89-%d8%b9%d9%84/\n",
      "262\n",
      "https://www.beamreports.com/2024/02/26/%d9%85%d8%a7-%d8%ad%d9%82%d9%8a%d9%82%d8%a9-%d8%ae%d8%b7%d8%a7%d8%a8-%d8%aa%d8%b9%d9%8a%d9%8a%d9%86-%d9%82%d9%8a%d8%a7%d8%af%d8%a7%d8%aa-%d9%85%d9%86-%d8%ad%d8%b1%d9%83%d8%a9-%d8%a7%d9%84%d8%b9/\n",
      "274\n",
      "https://www.beamreports.com/2024/01/28/%d9%85%d8%a7-%d8%b5%d8%ad%d8%a9-%d9%82%d8%b1%d8%a7%d8%b1-%d9%84%d9%84%d9%85%d8%ad%d9%83%d9%85%d8%a9-%d8%a7%d9%84%d8%b9%d9%84%d9%8a%d8%a7-%d9%8a%d9%82%d8%b6%d9%8a-%d8%a8%d8%b9%d9%88%d8%af/\n",
      "499\n",
      "https://www.beamreports.com/2022/03/16/%d9%85%d8%a7-%d8%b5%d8%ad%d8%a9-%d8%a7%d9%84%d9%85%d9%86%d8%b4%d9%88%d8%b1%d8%a7%d8%aa-%d9%88%d8%a7%d9%84%d8%b5%d9%88%d8%b1-%d8%a7%d9%84%d8%b1%d8%a7%d8%a6%d8%ac%d8%a9-%d8%ad%d9%88%d9%84-%d8%b5%d9%86/\n"
     ]
    }
   ],
   "source": [
    "# look at news urls with undefined account_url\n",
    "\n",
    "condition = (main_df['account_url'] == 'undefined')\n",
    "news_id_list = list(main_df[condition]['news_id'].unique())\n",
    "\n",
    "undefined_urls_df = urls_df[urls_df[\"news_id\"].isin(news_id_list)]\n",
    "news_num = undefined_urls_df.shape[0]\n",
    "\n",
    "for i in range(min(10,news_num)):\n",
    "    print(undefined_urls_df['news_id'].iloc[i])\n",
    "    print(undefined_urls_df['link'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d6de2f",
   "metadata": {},
   "source": [
    "be look at these four articles we found that :\n",
    "- news with id 499 are labeled news containing table that is not for accounts. so 6 rows must be removed\n",
    "- news with id 274, 262 and 258 has empty rows in a table. so 3 rows must be removed\n",
    "\n",
    "we will:\n",
    "- remove empty rows\n",
    "- put new with id 499 in a file called labeled_news_with_no_tables.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5231edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_label = main_df[main_df[\"news_id\"] == 499][\"label\"].iloc[0]\n",
    "temp_news_info= [{'news_id': 499,'label':temp_label}]\n",
    "labeled_news_no_tables_df = pd.DataFrame(temp_news_info)\n",
    "\n",
    "labeled_news_no_tables_df.to_csv(\"accounts_data/labeled_news_with_no_tables.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26fbb6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in main_df after removing unwanted rows:  1454\n"
     ]
    }
   ],
   "source": [
    "# removing rows with undefined urls\n",
    "condition = main_df[\"account_url\"] == 'undefined'\n",
    "main_df = main_df[~condition].reset_index(drop=True)\n",
    "\n",
    "print(\"number of rows in main_df after removing unwanted rows: \",main_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea7378fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of undefined labels:  0\n",
      "number of undefined accounts name :  0\n",
      "number of undefined followers_number :  1\n",
      "number of undefined account_url :  0\n"
     ]
    }
   ],
   "source": [
    "evaluate_df(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12ef7712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.beamreports.com/2023/04/15/%d9%85%d8%a7%d8%b5%d8%ad%d8%a9-%d8%a7%d9%84%d8%a8%d9%8a%d8%a7%d9%86-%d8%a7%d9%84%d9%85%d9%86%d8%b3%d9%88%d8%a8-%d8%a5%d9%84%d9%89-%d9%86%d8%a7%d8%b8%d8%b1-%d8%a7%d9%84%d8%b1%d8%b2%d9%8a%d9%82%d8%a7/\n"
     ]
    }
   ],
   "source": [
    "# see what row with undefined follower_number\n",
    "\n",
    "condition = main_df[\"followers_number\"] == 'undefined'\n",
    "main_df[condition].head()\n",
    "\n",
    "print(urls_df[urls_df[\"news_id\"] == 381][\"link\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f4d51a",
   "metadata": {},
   "source": [
    "we will not remove this row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2087713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save main_df\n",
    "main_df.to_csv(\"accounts_data/accounts_info_file_filtered_1.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e676e3",
   "metadata": {},
   "source": [
    "# Analyzing error log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "26cb7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_info_from_logs(path,pattern,start_idx,n):\n",
    "    '''\n",
    "    extracting news_id and error type from error log files\n",
    "    '''\n",
    "    \n",
    "    error_types = []\n",
    "    news_ids = []\n",
    "\n",
    "    for i in range(start_idx, n+1):\n",
    "        filename = pattern + str(i)+\".txt\"\n",
    "        try:\n",
    "            with open(path+filename, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "\n",
    "                # Match pattern like: [ErrorType] News ID: 123\n",
    "                matches = re.findall(r'\\[([^\\[\\]]+)\\]\\s+News ID\\s*:\\s*(\\d+)', content)\n",
    "\n",
    "                for error_type, news_id in matches:\n",
    "                    error_types.append(error_type)\n",
    "                    news_ids.append(int(news_id))\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "    return error_types, news_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab63bfd",
   "metadata": {},
   "source": [
    "extract news_id and error types from error log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7e0f24e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique error types:  ['MissingTable', 'RowParseError']\n",
      "number of unique news in the log error file:  166\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = os.getcwd()+\"/accounts_data/\"\n",
    "err_file_patt_string = \"error_log_file_\"\n",
    "start_idx = 1\n",
    "num_log_error_files = 11\n",
    "err_type_list, err_news_id_list = extract_info_from_logs(directory,err_file_patt_string,start_idx,num_log_error_files)\n",
    "\n",
    "err_types = list(set(err_type_list))\n",
    "err_news_id = list(set(err_news_id_list))\n",
    "\n",
    "print(\"unique error types: \", err_types)\n",
    "print(\"number of unique news in the log error file: \",len(err_news_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "70254500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news with row error: 13\n",
      "news with table error:  153\n"
     ]
    }
   ],
   "source": [
    "news_err_row = [news_id for news_id,err_type in zip(err_news_id_list,err_type_list) if err_type == 'RowParseError']\n",
    "news_err_row = list(set(news_err_row))\n",
    "news_err_table= list(set(err_news_id)-set(news_err_row))\n",
    "\n",
    "print(\"news with row error:\",len(news_err_row))\n",
    "print(\"news with table error: \",len(news_err_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8949323",
   "metadata": {},
   "source": [
    "### investigating news with Table errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "de87eca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.beamreports.com/2025/06/27/%d9%85%d8%a7-%d8%ad%d9%82%d9%8a%d9%82%d8%a9-%d8%b5%d9%88%d8%b1%d8%a9-%d8%a7%d9%84%d8%a8%d8%a7%d8%b5%d8%a7%d8%aa-%d8%a7%d9%84%d8%b3%d9%81%d8%b1%d9%8a%d8%a9-%d8%a7%d9%84%d8%b9%d8%a7%d8%a6%d8%af-2/\n",
      "https://www.beamreports.com/2025/01/24/%d9%85%d8%a7-%d8%ad%d9%82%d9%8a%d9%82%d8%a9-%d8%a7%d9%84%d8%aa%d8%b5%d8%b1%d9%8a%d8%ad-%d8%a7%d9%84%d9%85%d8%aa%d8%af%d8%a7%d9%88%d9%84-%d8%b9%d9%86-%d8%ad%d8%a7%d9%83%d9%85-%d8%a5%d9%82%d9%84%d9%8a/\n",
      "https://www.beamreports.com/2024/08/31/%d9%85%d8%a7-%d8%b5%d8%ad%d8%a9-%d8%a7%d8%af%d8%b9%d8%a7%d8%a1-%d8%a7%d9%84%d8%af%d8%b9%d9%85-%d8%a7%d9%84%d8%b3%d8%b1%d9%8a%d8%b9-%d8%a7%d9%84%d8%a5%d9%81%d8%b1%d8%a7%d8%ac-%d8%b9%d9%86/\n",
      "https://www.beamreports.com/2024/08/14/%d9%85%d8%a7-%d8%ad%d9%82%d9%8a%d9%82%d8%a9-%d8%a7%d9%84%d8%b5%d9%88%d8%b1-%d8%a7%d9%84%d9%85%d8%aa%d8%af%d8%a7%d9%88%d9%84%d8%a9-%d9%84%d9%84%d9%82%d8%a8%d8%b6-%d8%b9%d9%84%d9%89-%d9%85%d8%b5%d8%b1/\n"
     ]
    }
   ],
   "source": [
    "condition = urls_df[\"news_id\"].isin(news_err_table)\n",
    "df_mis_table_urls = urls_df[condition].reset_index(drop=True).sort_values(by=\"news_id\",ascending=True)\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    print(df_mis_table_urls[\"link\"].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540882c3",
   "metadata": {},
   "source": [
    "After reviewing some sample news items with table errors, we found that they are either reports and investigations that do not contain a news table, or actual news articles that are simply missing the table.\n",
    "\n",
    "We will separate the news articles with missing tables into a separate file for further investigation. These can be identified by the presence of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8637c285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of extracted labeled_news with no tables:  153\n",
      "number of extracted ulabeled_news with no tables:  0\n"
     ]
    }
   ],
   "source": [
    "labeled_news_info_list = []\n",
    "unlabeled_news_info_list=[]\n",
    "\n",
    "news_link_pairs = zip(df_mis_table_urls[\"news_id\"],df_mis_table_urls[\"link\"])\n",
    "\n",
    "for crr_news_id,current_url in news_link_pairs: \n",
    "\n",
    "    response = requests.get(current_url, timeout=10)\n",
    "    response.raise_for_status()\n",
    "    html_text = response.text\n",
    "    soup = BeautifulSoup(html_text, 'lxml')\n",
    "    \n",
    "    temp_divs = soup.find_all(\n",
    "        'div',\n",
    "        attrs={\n",
    "            'data-element_type': \"widget\",\n",
    "            'data-widget_type': \"icon-list.default\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        label = temp_divs[1].text.strip()\n",
    "\n",
    "        if label:\n",
    "            news_info ={\n",
    "                'label': label,\n",
    "                'news_id': crr_news_id\n",
    "            }\n",
    "            labeled_news_info_list.append(news_info)\n",
    "        else:\n",
    "            raise ValueError(\"Label text is empty.\")\n",
    "    except:\n",
    "        unlabeled_news_info_list.append(current_news_id)\n",
    "        continue\n",
    "\n",
    "print(\"number of extracted labeled_news with no tables: \",len(labeled_news_info_list))\n",
    "print(\"number of extracted ulabeled_news with no tables: \",len(unlabeled_news_info_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c929b883",
   "metadata": {},
   "source": [
    "- saving news with no labels in a file called \"news_no_labels_file.csv\"\n",
    "- saving news with lables and without table in file called \"labeled_news_with_no_tables.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "57dc22bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>news_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>مفبرك</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>مفبرك</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>مضلل</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مضلل</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مضلل</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  news_id\n",
       "0  مفبرك       19\n",
       "1  مفبرك      100\n",
       "2   مضلل      159\n",
       "3   مضلل      170\n",
       "4   مضلل      178"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.DataFrame(labeled_news_info_list)\n",
    "\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "60f2ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_news_no_tables_df = pd.read_csv(\"accounts_data/labeled_news_with_no_tables.csv\")\n",
    "\n",
    "labeled_news_no_tables_df = pd.concat([labeled_news_no_tables_df,temp_df]).reset_index(drop=True).sort_values(by=\"news_id\",ascending=True)\n",
    "labeled_news_no_tables_df.to_csv(\"accounts_data/labeled_news_with_no_tables.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f35de6",
   "metadata": {},
   "source": [
    "### investigating news with row errors:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baff2433",
   "metadata": {},
   "source": [
    "looking at the structure of rows to identify new way to capture information from a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "65890bc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "https://www.beamreports.com/2025/06/19/%d9%85%d8%a7-%d8%ad%d9%82%d9%8a%d9%82%d8%a9-%d8%aa%d8%b5%d8%b1%d9%8a%d8%ad-%d9%85%d9%86%d8%b3%d9%88%d8%a8-%d9%84%d8%b1%d8%a6%d9%8a%d8%b3-%d8%a7%d9%84%d9%88%d8%b2%d8%b1%d8%a7%d8%a1-%d9%83%d8%a7%d9%85/\n",
      "63\n",
      "https://www.beamreports.com/2025/04/04/%d9%85%d8%a7-%d8%ad%d9%82%d9%8a%d9%82%d8%a9-%d8%aa%d9%88%d8%b9%d9%91%d8%af-%d9%88%d8%b2%d9%8a%d8%b1-%d8%a7%d9%84%d8%af%d9%81%d8%a7%d8%b9-%d8%a7%d9%84%d9%85%d8%b5%d8%b1%d9%8a-%d8%a8%d8%a7%d9%84%d8%aa/\n",
      "95\n",
      "https://www.beamreports.com/2025/02/02/%d9%85%d8%a7-%d8%ad%d9%82%d9%8a%d9%82%d8%a9-%d8%a7%d9%84%d9%81%d9%8a%d8%af%d9%8a%d9%88-%d8%a7%d9%84%d9%85%d8%aa%d8%af%d8%a7%d9%88%d9%84-%d8%b9%d9%84%d9%89-%d8%a3%d9%86%d9%87-%d8%a7%d8%b4%d8%aa%d8%a8/\n",
      "144\n",
      "https://www.beamreports.com/2024/09/28/%d9%85%d8%a7-%d8%ad%d9%82%d9%8a%d9%82%d8%a9-%d9%85%d9%82%d8%b7%d8%b9-%d8%a7%d9%84%d9%81%d9%8a%d8%af%d9%8a%d9%88-%d8%a7%d9%84%d9%85%d8%aa%d8%af%d8%a7%d9%88%d9%84-%d8%b9%d9%84%d9%89-%d8%a3%d9%86%d9%87-6/\n",
      "250\n",
      "https://www.beamreports.com/2024/03/26/%d9%85%d8%a7-%d8%b5%d8%ad%d8%a9-%d8%aa%d8%b5%d8%b1%d9%8a%d8%ad-%d9%8a%d8%a7%d8%b3%d8%b1-%d8%b9%d8%b1%d9%85%d8%a7%d9%86-%d9%86%d8%b1%d8%ad%d8%a8-%d8%a8%d9%80%d9%85%d9%88%d8%a7%d9%81/\n",
      "269\n",
      "https://www.beamreports.com/2024/02/14/%d9%85%d8%a7-%d8%ad%d9%82%d9%8a%d9%82%d8%a9-%d8%aa%d8%b5%d8%b1%d9%8a%d8%ad-%d8%a7%d9%84%d8%a8%d8%b1%d9%87%d8%a7%d9%86-%d8%a8%d9%85%d8%af%d9%8a%d9%86%d8%a9-%d8%a7%d9%84%d8%af%d8%a8%d8%a9/\n",
      "292\n",
      "https://www.beamreports.com/2023/12/22/%d9%85%d8%a7-%d8%ad%d9%82%d9%8a%d9%82%d8%a9%d9%8f-%d9%85%d9%82%d8%b7%d8%b9-%d9%81%d9%8a%d8%af%d9%8a%d9%88-%d8%ad%d9%88%d9%84-%d9%85%d8%ac%d8%b2%d8%b1%d8%a9-%d8%a7%d8%b1%d8%aa%d9%83%d8%a8%d9%87%d8%a7/\n",
      "386\n",
      "https://www.beamreports.com/2023/04/13/%d9%85%d8%a7-%d8%b5%d8%ad%d8%a9-%d8%ba%d9%8e%d9%84%d9%82-%d8%ac%d9%85%d9%8a%d8%b9-%d8%a7%d9%84%d8%b7%d8%b1%d9%82-%d8%a7%d9%84%d9%85%d8%a4%d8%af%d9%8a%d8%a9-%d8%a5%d9%84%d9%89-%d8%a7%d9%84%d9%82%d9%8a/\n",
      "392\n",
      "https://www.beamreports.com/2023/03/13/%d9%85%d8%a7-%d8%ad%d9%82%d9%8a%d9%82%d8%a9-%d8%a7%d8%aa%d9%81%d8%a7%d9%82-%d8%a7%d9%84%d8%ad%d8%b1%d9%8a%d8%a9-%d9%88%d8%a7%d9%84%d8%aa%d8%ba%d9%8a%d9%8a%d8%b1-%d9%85%d8%b9-%d8%ad%d9%85%d8%af%d9%88/\n",
      "393\n",
      "https://www.beamreports.com/2023/03/09/%d9%85%d8%a7-%d8%b5%d8%ad%d8%a9-%d8%aa%d8%b5%d8%b1%d9%8a%d8%ad-%d8%a7%d9%84%d8%a5%d8%b9%d9%84%d8%a7%d9%85%d9%8a-%d9%85%d8%b5%d8%b7%d9%81%d9%89-%d8%a8%d9%83%d8%b1%d9%8a-%d8%b9%d9%86-%d8%a5%d8%af/\n",
      "395\n",
      "https://www.beamreports.com/2023/02/22/%d9%85%d8%a7-%d8%b5%d8%ad%d8%a9-%d8%aa%d9%88%d9%84%d9%8a-%d9%83%d8%a8%d8%a7%d8%b4%d9%8a-%d9%85%d9%86%d8%b5%d8%a8-%d9%86%d8%a7%d8%a6%d8%a8-%d8%b1%d8%a6%d9%8a%d8%b3-%d8%a7%d9%84%d9%85%d8%ac%d9%84/\n",
      "415\n",
      "https://www.beamreports.com/2023/01/08/%d9%85%d8%a7-%d8%b5%d8%ad%d8%a9-%d8%a7%d9%84%d8%b5%d9%88%d8%b1%d8%a9-%d8%a7%d9%84%d9%85%d8%aa%d8%af%d8%a7%d9%88%d9%84%d8%a9-%d9%84%d8%b9%d9%88%d8%af%d8%a9-%d8%ad%d9%85%d8%af%d9%88%d9%83-%d8%a5%d9%84/\n",
      "424\n",
      "https://www.beamreports.com/2022/12/08/%d9%85%d8%a7-%d8%ad%d9%82%d9%8a%d9%82%d8%a9-%d8%a7%d9%84%d8%aa%d8%b5%d8%b1%d9%8a%d8%ad-%d8%a7%d9%84%d9%85%d9%86%d8%b3%d9%88%d8%a8-%d9%84%d9%81%d9%88%d9%84%d9%83%d8%b1-%d8%b9%d9%86-%d8%a3%d9%86-%d8%b3/\n"
     ]
    }
   ],
   "source": [
    "condition = urls_df[\"news_id\"].isin(news_err_row)\n",
    "df_row_err_urls = urls_df[condition].reset_index(drop=True).sort_values(by=\"news_id\",ascending=True)\n",
    "\n",
    "for i in range(len(news_err_row)):\n",
    "    print(df_row_err_urls[\"news_id\"].iloc[i])\n",
    "    print(df_row_err_urls[\"link\"].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98cce3a",
   "metadata": {},
   "source": [
    "after looking at some pages,there is tables that used the tag < th > instead of < td > , and there is a tables with two columns (account and number of followers)instead of three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "212fbd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts = []\n",
    "unlabeled_news = []\n",
    "labeled_news_no_accounts = []\n",
    "\n",
    "news_link_pairs = zip(df_row_err_urls[\"news_id\"], df_row_err_urls[\"link\"])\n",
    "\n",
    "for current_news_id, current_url in news_link_pairs: \n",
    "\n",
    "    response = requests.get(current_url, timeout=10)\n",
    "    response.raise_for_status()\n",
    "    html_text = response.text\n",
    "    soup = BeautifulSoup(html_text, 'lxml')\n",
    "\n",
    "    temp_divs = soup.find_all(\n",
    "        'div',\n",
    "        attrs={\n",
    "            'data-element_type': \"widget\",\n",
    "            'data-widget_type': \"icon-list.default\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        label = temp_divs[1].get_text(strip=True) if len(temp_divs) > 1 else \"\"\n",
    "\n",
    "        if not (label and label.replace(\"\\xa0\", \"\").strip()):\n",
    "            raise ValueError(\"Label text is empty.\")\n",
    "    except:\n",
    "        unlabeled_news.append(current_news_id)\n",
    "        continue\n",
    "\n",
    "    table = soup.find('table')\n",
    "    if not table:\n",
    "        labeled_news_no_accounts.append(current_news_id)\n",
    "        continue\n",
    "\n",
    "    tr_elements = table.find_all('tr')\n",
    "\n",
    "    def clean_text(element):\n",
    "        \"\"\"Safely extract text content from an HTML element, replacing &nbsp; and stripping whitespace.\"\"\"\n",
    "        if element:\n",
    "            text = element.get_text()\n",
    "            if text and text.replace('\\xa0', '').strip():\n",
    "                return text.replace('\\xa0', ' ').strip()\n",
    "        return 'undefined'\n",
    "                \n",
    "    for r, tr in enumerate(tr_elements):\n",
    "        try:\n",
    "            th_elements = tr.find_all('th')\n",
    "            td_elements = tr.find_all('td')\n",
    "\n",
    "            account_info = {\n",
    "                'row_table_number': r+1,\n",
    "                'account_url': 'undefined',\n",
    "                'account_name': 'undefined',\n",
    "                'followers_number': 'undefined',\n",
    "                'label': label,\n",
    "                'news_id': current_news_id\n",
    "            }\n",
    "\n",
    "            if th_elements and len(th_elements) >= 3:\n",
    "                if th_elements[1].select_one('a'):\n",
    "                    account_info['account_url'] = th_elements[1].select_one('a')['href']\n",
    "                    account_info['account_name'] = clean_text(th_elements[1])\n",
    "                    account_info['followers_number'] = clean_text(th_elements[2])\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            elif td_elements and len(td_elements) >= 3:\n",
    "                #already caputered in the last first extract proccess\n",
    "                continue\n",
    "\n",
    "            elif td_elements and len(td_elements) == 2:\n",
    "                if td_elements[0].select_one('a'):\n",
    "                    account_info['account_url'] = td_elements[0].select_one('a')['href']\n",
    "                    account_info['account_name'] = clean_text(td_elements[0])\n",
    "                    account_info['followers_number'] = clean_text(td_elements[1])\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            else:\n",
    "                if current_news_id not in labeled_news_no_accounts:\n",
    "                    labeled_news_no_accounts.append(current_news_id)\n",
    "                continue\n",
    "\n",
    "            accounts.append(account_info)\n",
    "\n",
    "        except Exception as e:\n",
    "            if current_news_id not in labeled_news_no_accounts:\n",
    "                labeled_news_no_accounts.append(current_news_id)\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1d976b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of extracted accounts:  40\n",
      "number of unlabeled news: 0\n",
      "number of labeled news with no accounts 0\n"
     ]
    }
   ],
   "source": [
    "print(\"number of extracted accounts: \",len(accounts))\n",
    "print(\"number of unlabeled news:\",len(unlabeled_news))\n",
    "print(\"number of labeled news with no accounts\",len(labeled_news_no_accounts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "06bebdc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_table_number</th>\n",
       "      <th>account_url</th>\n",
       "      <th>account_name</th>\n",
       "      <th>followers_number</th>\n",
       "      <th>label</th>\n",
       "      <th>news_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://web.facebook.com/share/p/1BxwcLf8HN/</td>\n",
       "      <td>قوات العمل الخاص و هيئة العمليات 🇸🇩</td>\n",
       "      <td>(690) ألف متابع</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://web.facebook.com/share/p/19BBYkPd1t/</td>\n",
       "      <td>تجمع رحالين ترحال ليمون قو فرس</td>\n",
       "      <td>(569) ألف متابع</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://web.facebook.com/share/p/152CG2uU52o/</td>\n",
       "      <td>الجيش السوداني 🇸🇩</td>\n",
       "      <td>(361) ألف متابع</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://web.facebook.com/share/p/196YnjFB9d/</td>\n",
       "      <td>الانصرافي</td>\n",
       "      <td>(159) ألف متابع</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>https://web.facebook.com/groups/57262537958967...</td>\n",
       "      <td>الراكوبـــــه الســـــودانيه( ❤بيتنا الكبير يل...</td>\n",
       "      <td>(850) ألف متابع</td>\n",
       "      <td>مفبرك</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_table_number                                        account_url  \\\n",
       "0                 1       https://web.facebook.com/share/p/1BxwcLf8HN/   \n",
       "1                 2       https://web.facebook.com/share/p/19BBYkPd1t/   \n",
       "2                 3      https://web.facebook.com/share/p/152CG2uU52o/   \n",
       "3                 4       https://web.facebook.com/share/p/196YnjFB9d/   \n",
       "4                 1  https://web.facebook.com/groups/57262537958967...   \n",
       "\n",
       "                                        account_name followers_number  label  \\\n",
       "0                قوات العمل الخاص و هيئة العمليات 🇸🇩  (690) ألف متابع  مفبرك   \n",
       "1                     تجمع رحالين ترحال ليمون قو فرس  (569) ألف متابع  مفبرك   \n",
       "2                                  الجيش السوداني 🇸🇩  (361) ألف متابع  مفبرك   \n",
       "3                                          الانصرافي  (159) ألف متابع  مفبرك   \n",
       "4  الراكوبـــــه الســـــودانيه( ❤بيتنا الكبير يل...  (850) ألف متابع  مفبرك   \n",
       "\n",
       "   news_id  \n",
       "0       22  \n",
       "1       22  \n",
       "2       22  \n",
       "3       22  \n",
       "4       63  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_df = pd.DataFrame(accounts)\n",
    "accounts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7adbced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.concat([main_df,accounts_df],ignore_index=True).sort_values(by=[\"news_id\",\"row_table_number\"],ascending=[True,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c14b7a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of undefined labels:  0\n",
      "number of undefined accounts name :  0\n",
      "number of undefined followers_number :  1\n",
      "number of undefined account_url :  0\n"
     ]
    }
   ],
   "source": [
    "evaluate_df(main_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b007e81",
   "metadata": {},
   "source": [
    "#### merge extracted accounts with main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dc2e52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save main_df\n",
    "main_df.to_csv(\"accounts_data/accounts_info_file_filtered_extended_1.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "953ecb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_label_df = pd.read_csv(\"accounts_data/news_no_labels_file.csv\")\n",
    "no_label_df.columns = [\"news_id\"]\n",
    "no_label_df.to_csv(\"accounts_data/news_no_labels_file.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7347686",
   "metadata": {},
   "source": [
    "#### check if there is any news not included on any file yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ba03ae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of extracted news: 546 , total number of news: 547 \n"
     ]
    }
   ],
   "source": [
    "main_df = pd.read_csv(\"accounts_data/accounts_info_file_filtered_extended_1.csv\")\n",
    "label_no_table_df = pd.read_csv(\"accounts_data/labeled_news_with_no_tables.csv\")\n",
    "no_label_df = pd.read_csv(\"accounts_data/news_no_labels_file.csv\")\n",
    "urls_df =  pd.read_excel(\"news_id_url.xlsx\")\n",
    "#df4 = pd.read_csv(\"accounts_data/accounts_info_file_merged.csv\")\n",
    "#intersection\n",
    "\n",
    "def unq_news_id(df):\n",
    "    return list(df[\"news_id\"].unique())\n",
    "    \n",
    "unq1 = unq_news_id(main_df)\n",
    "unq2 = unq_news_id(label_no_table_df)\n",
    "unq3 = unq_news_id(no_label_df)\n",
    "total_news = unq_news_id(urls_df)\n",
    "\n",
    "sum_news_number = len(unq1)+len(unq2)+len(unq3)\n",
    "all_news_number = len(total_news)\n",
    "\n",
    "print(f\"sum of extracted news: {sum_news_number} , total number of news: {all_news_number} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "50f0dabe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_listed = set(total_news) - set(unq1+unq2+unq3)\n",
    "temp_df = pd.DataFrame(not_listed)\n",
    "label_no_table_df = pd.concat([label_no_table_df,temp_df], ignore_index=True)\n",
    "label_no_table_df.to_csv(\"accounts_data/labeled_news_with_no_tables.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efaaae6",
   "metadata": {},
   "source": [
    "We finished the process of extracting accounts from beam report website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf673c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
